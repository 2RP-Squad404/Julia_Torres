# Linguagens e Frameworks
## Python
É uma linguagem de programação de alto nível cohecida pela sua simplicidade e legibilidade.

### Características:
* Sintaxe Simples;
* Interpretação e Portabilidade;
* Bibliotecas e Framewoks Ricos;
*B Comunidade Ativa.

## Introdução ao Apache Sparks
É um framework de processamento de dados de grandes escalas, projetado para um processamento rápido e geral.

### PySpark:
PySpark é uma ligação entre o Apache Spark para a linguagem de programação Python. 

### Caraterísticas:
* Processamento em Memória;
* API Unificada para Diferentes Tipos de Análise;
* Escalabilidade e Distribuição;
* Suporte a Vária Linguagens;
* Facilidade de Integração.

### Benefícios:
* Desempenho;
* Versatilidade;
* Facilidade de Uso;
* Comunidade Ativa.

## Introdução ao Apache Beam e Google Dataflow
São ferramentas para o processamento de dados em uma larga escala. Apache Beam é um modelo de programação que permite definir pipelines de dados e o Dataflow é um serviço do Google Cloud para executa as pipelines.

### Características Apache Beam:
* Modelo Unificado;
* Portabilidade;
* API Flexível;
* Transformações;
* Janelas e Watermarks.

### Características Google Dataflow:
* Gerenciamento Totalmente;
* Escalabilidade Automática;
* Integração com Google Cloud;
* Visualização e Monitoramento;
* Modelo de Preços Baseado em Uso.

### Benefícios
#### Apache Beam:
* Portabilidade;
* Flexibilidade;
* Comunidade Ativa.

#### Google Dataflow:
* Simplicidade de Uso;
* Integração com Google Cloud;
* Escalabilidade.

## Introdução ao Apache Airflow
Serve para orquestração e automação de workflows de dados.

### Características:
* Definição de Workflow como Código;
* Interface Web;
* Agendamento Flexível;
* Execução Paralela e Escalabilidade;
* Retry e Resiliência.

### Componentes Principais:
* DAG (Directed Acyclic Graph);
* Operadores;
* Tasks;
* Scheduler;
* Executor;
* Web Interface.

### Benefícios:
* Flexibilidade;
* Escalabilidade;
* Visibilidade e Monitoramento;
* Comunidade Ativa.
